{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Análise de Sentimentos dos comentários do IMDB</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from skopt import forest_minimize\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='IND'></a>\n",
    "<h2>Índice</h2>\n",
    "<font size=3>\n",
    "<ol>\n",
    "    <li><a href='#SETDATA'>Montando o dataset</a></li>\n",
    "    <ol>\n",
    "        <li><a href='#DATATRAIN'>Dataset de Treino</a></li>\n",
    "        <li><a href='#DATATEST'>Dataset de Teste</a></li>\n",
    "    </ol>\n",
    "    <li><a href='#PREPRO'>Pré-processamento</a></li>\n",
    "    <li><a href='#LR'>Regressão Logística</a></li>\n",
    "    <li><a href='#RF'>Random Forrest</a></li>\n",
    "    <li><a href='#LGBM'>LightGBM</a></li>\n",
    "    <li><a href='#BAYES'>Bayesian Optimization</a></li>\n",
    "    <li><a href='#VOT'>Voting</a></li>\n",
    "</ol>\n",
    "</font>\n",
    "\n",
    "<a name='SETDATA'></a>\n",
    "<h2>Montando o dataset</h2>\n",
    "<font size=3>Como os comentários dos filmes estão em diferentes arquivos <i>.txt</i> vamos ter que agregar todos os comentários em um dataset. Com isso criamos uma função que irá limpar os comentários e retirar as <i>stop words</i>.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(comment):\n",
    "    stop_words = pd.read_csv('./stop-words.csv', header=None)\n",
    "    stop_words = stop_words[0].values\n",
    "    word2word = comment.split(sep=' ')      # Divide o comentário por palavra\n",
    "    for word in word2word:\n",
    "        if word in stop_words:\n",
    "            word2word.remove(word)          # Remove a palavra se ela for uma stop word\n",
    "    return ' '.join(word2word)              # Junta as palavras que sobraram do comentário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Agora com a função de limpeza dos comentários feita, vamos criar a função para agregar os comentários de um diretório específico</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commentaries(path):\n",
    "    files = os.listdir(path)                                 # Pega todos os nomes dos arquivos do diretório\n",
    "    break_line = re.compile('(<br /><br />)')                # Compila um padrão de expressão regular de quebra de linha \n",
    "    character =  re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")            # Compila um padrão de expressão regular de acentuação\n",
    "    comm_list = []\n",
    "    for file in files:\n",
    "        nota = file[-5]                                      # Pega a nota que o usuário deu para o filme\n",
    "        if nota=='0':\n",
    "            nota = '10'\n",
    "        with open(path+file, 'r') as file:\n",
    "            comment = file.read()                            # Lê o comentário\n",
    "            comment = break_line.sub(' ', comment)           # Substitui a quebra de linha em espaço\n",
    "            comment = character.sub('', comment)             # Substitui a acentuação por nada\n",
    "            comment = comment.lower()                        # Deixa todos os caracteres em minúsculo\n",
    "            comment = remove_stop_words(comment)             # Remove as stop words\n",
    "            comm_list.append([comment, nota])\n",
    "    df = pd.DataFrame(comm_list, columns=['Comments', 'Rating'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Função feita vamos pegar os comentários nos seguintes diretórios:\n",
    "<ul>\n",
    "    <li>./aclimdb/train/neg/</li>\n",
    "    <li>./aclimdb/train/pos/</li>\n",
    "    <li>./aclimdb/test/neg/</li>\n",
    "    <li>./aclimdb/test/pos/</li>\n",
    "</ul>\n",
    "</font>\n",
    "<a name=DATATRAIN></a>\n",
    "<h3>Dataset de Treino</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dataset: (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dir = ['./aclimdb/train/neg/', './aclimdb/train/pos/']\n",
    "df_train = pd.DataFrame()\n",
    "for directory in train_dir:\n",
    "    temp_df = get_commentaries(directory)\n",
    "    df_train = pd.concat([df_train, temp_df], ignore_index=True)\n",
    "print('Tamanho do dataset: {}'.format(df_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='DATATEST'></a>\n",
    "<h3>Dataset de Teste</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dataset: (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dir = ['./aclimdb/test/neg/', './aclimdb/test/pos/']\n",
    "df_test = pd.DataFrame()\n",
    "for directory in train_dir:\n",
    "    temp_df = get_commentaries(directory)\n",
    "    df_test = pd.concat([df_test, temp_df], ignore_index=True)\n",
    "print('Tamanho do dataset: {}'.format(df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='PREPRO'></a>\n",
    "<h2>Pré-processamento</h2>\n",
    "<font size=3>Vamos ajustar a variável alvo, definindo como 1 para comentário <b>bom</b> e 0 para comentário <b>ruim</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rating'] = df_train['Rating'].astype(int)\n",
    "df_train['Target'] = df_train['Rating'].apply(lambda x: 1 if x > 6 else 0)\n",
    "df_test['Rating'] = df_train['Rating'].astype(int)\n",
    "df_test['Target'] = df_test['Rating'].apply(lambda x: 1 if x > 6 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Agora dividiremos em <b>X</b> e <b>Y</b>.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = df_train['Comments']\n",
    "ytrain = df_train['Target']\n",
    "Xtest = df_test['Comments']\n",
    "ytest = df_test['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Com a divisão feita, vamos utilizar o <i>TfidfVectorizer</i>.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain:\t(25000,)\n",
      "Xtest:\t(25000,)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=2, ngram_range=(1,1))\n",
    "Xtrain_vec = tfidf.fit_transform(Xtrain)\n",
    "Xtest_vec = tfidf.transform(Xtest)\n",
    "print('Xtrain:\\t{}\\nXtest:\\t{}'.format(Xtrain.shape, Xtest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='LR'></a>\n",
    "<h2>Regressão Logística</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc:\t0.88416\n",
      "accuracy:\t0.88416\n",
      "f1 score:\t0.8841321917260143\n",
      "avg precision:\t0.8397297774931968\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=79)\n",
    "lr.fit(Xtrain_vec, ytrain)\n",
    "ypred_lr = lr.predict(Xtest_vec)\n",
    "roc_auc_lr = roc_auc_score(ytest, ypred_lr)\n",
    "acc_lr = accuracy_score(ytest, ypred_lr)\n",
    "f1_lr = f1_score(ytest, ypred_lr)\n",
    "avg_prec_lr = average_precision_score(ytest, ypred_lr)\n",
    "print('roc auc:\\t{}\\naccuracy:\\t{}\\nf1 score:\\t{}\\navg precision:\\t{}'.format(roc_auc_lr, acc_lr, f1_lr, avg_prec_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='RF'></a>\n",
    "<h2>Random Forrest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc:\t0.8586800000000001\n",
      "accuracy:\t0.85868\n",
      "f1 score:\t0.8583116101864849\n",
      "avg precision:\t0.808663826296743\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, min_samples_leaf=2, class_weight='balanced', n_jobs=5, random_state=79)\n",
    "rf.fit(Xtrain_vec, ytrain)\n",
    "ypred_rf = rf.predict(Xtest_vec)\n",
    "roc_auc_fr = roc_auc_score(ytest, ypred_rf)\n",
    "acc_fr = accuracy_score(ytest, ypred_rf)\n",
    "f1_fr = f1_score(ytest, ypred_rf)\n",
    "avg_prec_fr = average_precision_score(ytest, ypred_rf)\n",
    "print('roc auc:\\t{}\\naccuracy:\\t{}\\nf1 score:\\t{}\\navg precision:\\t{}'.format(roc_auc_fr, acc_fr, f1_fr, avg_prec_fr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='LGBM'></a>\n",
    "<h2>LightGBM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc:\t0.86104\n",
      "accuracy:\t0.86104\n",
      "f1 score:\t0.8625138515117935\n",
      "avg precision:\t0.8081338408521304\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(random_state=79, class_weight='balanced', n_jobs=5)\n",
    "lgbm.fit(Xtrain_vec, ytrain)\n",
    "ypred_lgbm = lgbm.predict(Xtest_vec)\n",
    "roc_auc_lgbm = roc_auc_score(ytest, ypred_lgbm)\n",
    "acc_lgbm = accuracy_score(ytest, ypred_lgbm)\n",
    "f1_lgbm = f1_score(ytest, ypred_lgbm)\n",
    "avg_prec_lgbm = average_precision_score(ytest, ypred_lgbm)\n",
    "print('roc auc:\\t{}\\naccuracy:\\t{}\\nf1 score:\\t{}\\navg precision:\\t{}'.format(roc_auc_lgbm, acc_lgbm,\n",
    "                                                                              f1_lgbm, avg_prec_lgbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='BAYES'></a>\n",
    "<h2>Bayesian Optimization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.006292827825947035, 4, 19, 0.46248056016314054, 0.8805011161066282, 827, 3, 4]\n",
      "0.7979999999999999\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 155.6676\n",
      "Function value obtained: -0.7271\n",
      "Current minimum: -0.7271\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.04267373105004074, 3, 16, 0.1261298714290931, 0.998324765488932, 163, 3, 5]\n",
      "0.80608\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 130.3084\n",
      "Function value obtained: -0.7366\n",
      "Current minimum: -0.7366\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.008175050624738778, 7, 5, 0.2915815679278623, 0.6808984760418078, 497, 5, 4]\n",
      "0.814\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 254.6230\n",
      "Function value obtained: -0.7466\n",
      "Current minimum: -0.7466\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.013777428975026594, 1, 3, 0.8384254088062836, 0.6808661755213409, 628, 5, 1]\n",
      "0.756\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 22.0138\n",
      "Function value obtained: -0.6811\n",
      "Current minimum: -0.7466\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.02063947241056242, 7, 5, 0.5560139969852448, 0.7680592845640004, 851, 2, 2]\n",
      "0.8604400000000001\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 320.7550\n",
      "Function value obtained: -0.8064\n",
      "Current minimum: -0.8064\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.07557266625861911, 4, 12, 0.6271121227456883, 0.1203944336835415, 870, 1, 4]\n",
      "0.86668\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 186.4354\n",
      "Function value obtained: -0.8154\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.0425716138941407, 6, 12, 0.6680327549655113, 0.5337438591279371, 539, 3, 3]\n",
      "0.8598000000000001\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 140.9890\n",
      "Function value obtained: -0.8048\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.012003061293981479, 8, 17, 0.5964168742420323, 0.26260140832327833, 399, 5, 1]\n",
      "0.8236000000000001\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 48.8822\n",
      "Function value obtained: -0.7577\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.005835377162910052, 7, 15, 0.41306744877914203, 0.4059709949240141, 768, 5, 1]\n",
      "0.81632\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 75.2297\n",
      "Function value obtained: -0.7486\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.0015217756648041585, 4, 11, 0.6464639633594784, 0.107850916199107, 126, 4, 5]\n",
      "0.7918799999999999\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 135.5635\n",
      "Function value obtained: -0.7200\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[0.004650188351168763, 10, 19, 0.12198580117009171, 0.1059038542544117, 923, 4, 2]\n",
      "0.84484\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 98.8602\n",
      "Function value obtained: -0.7844\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[0.009907098875752552, 9, 5, 0.7778400405320561, 0.8495656982064982, 222, 1, 2]\n",
      "0.7936\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 290.0727\n",
      "Function value obtained: -0.7237\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[0.005010431991490294, 6, 16, 0.08886521885353486, 0.8885267657177083, 294, 5, 2]\n",
      "0.77328\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 53.7580\n",
      "Function value obtained: -0.6995\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[0.00896138736201577, 10, 4, 0.5239007714522997, 0.054782979033892676, 547, 5, 1]\n",
      "0.8528399999999999\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 96.1838\n",
      "Function value obtained: -0.7949\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[0.0011328698698126922, 9, 13, 0.9035935728750635, 0.19480315265820664, 629, 1, 3]\n",
      "0.8109600000000001\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 261.2362\n",
      "Function value obtained: -0.7434\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[0.004741779351894459, 3, 19, 0.47586235135673066, 0.32165916970494635, 699, 4, 1]\n",
      "0.7676799999999999\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 29.0103\n",
      "Function value obtained: -0.6937\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[0.015876373018161985, 5, 5, 0.9780924881472546, 0.3231366231499029, 295, 2, 3]\n",
      "0.80064\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 128.9722\n",
      "Function value obtained: -0.7308\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[0.008920340799848535, 5, 8, 0.4962342783691298, 0.28979773721729435, 419, 5, 4]\n",
      "0.79552\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 143.2978\n",
      "Function value obtained: -0.7244\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[0.009570050455150912, 10, 13, 0.4799771234081137, 0.8128345330943129, 404, 4, 1]\n",
      "0.82116\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 117.5581\n",
      "Function value obtained: -0.7557\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[0.012189803613943551, 8, 3, 0.5583164166745482, 0.23674900499166723, 244, 2, 3]\n",
      "0.81464\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 261.5680\n",
      "Function value obtained: -0.7475\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "[0.038736384188271, 3, 8, 0.3727724666306476, 0.08364436170206235, 982, 2, 2]\n",
      "0.86228\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 72.3897\n",
      "Function value obtained: -0.8073\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "[0.04274070800210521, 2, 2, 0.4027540803789716, 0.8058362696098793, 886, 1, 1]\n",
      "0.8476\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 44.2791\n",
      "Function value obtained: -0.7871\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "[0.04008307942546136, 1, 9, 0.9163189883491467, 0.09949351919549089, 922, 5, 1]\n",
      "0.8159200000000001\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 19.5472\n",
      "Function value obtained: -0.7467\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "[0.07725072300273327, 3, 1, 0.5080034242260305, 0.473395977338625, 749, 2, 1]\n",
      "0.8682799999999999\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 48.5273\n",
      "Function value obtained: -0.8145\n",
      "Current minimum: -0.8154\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "[0.06270171153666912, 5, 14, 0.790629009747611, 0.31944859215112925, 721, 2, 4]\n",
      "0.87036\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 160.3138\n",
      "Function value obtained: -0.8195\n",
      "Current minimum: -0.8195\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "[0.0748052629672294, 5, 20, 0.9604542539145369, 0.445918719969433, 594, 2, 1]\n",
      "0.86592\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 43.5339\n",
      "Function value obtained: -0.8118\n",
      "Current minimum: -0.8195\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "[0.09431638480128277, 4, 3, 0.6295926398680836, 0.34512927281549965, 815, 3, 1]\n",
      "0.8740799999999999\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.5761\n",
      "Function value obtained: -0.8231\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "[0.09902973440487717, 4, 17, 0.7744919361521229, 0.4865157031332132, 713, 4, 1]\n",
      "0.8713599999999999\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 41.3380\n",
      "Function value obtained: -0.8195\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "[0.08009725880222562, 4, 9, 0.8691753357624316, 0.9054429630646575, 722, 5, 1]\n",
      "0.868\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 63.1755\n",
      "Function value obtained: -0.8145\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "[0.09008805312291457, 3, 1, 0.6628247697676046, 0.3442827230864346, 495, 4, 1]\n",
      "0.85988\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 30.9432\n",
      "Function value obtained: -0.8033\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "[0.07860686823355727, 1, 14, 0.7551361771126929, 0.5570522399081357, 667, 5, 3]\n",
      "0.8324\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 77.4596\n",
      "Function value obtained: -0.7676\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "[0.07076302850280224, 4, 18, 0.563725261976527, 0.3938681021866563, 174, 3, 1]\n",
      "0.82776\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 16.3639\n",
      "Function value obtained: -0.7621\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "[0.033203571355958326, 4, 7, 0.8756483834171999, 0.36066953420115183, 705, 2, 1]\n",
      "0.8479599999999999\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 46.8134\n",
      "Function value obtained: -0.7877\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "[0.09004629293712364, 5, 10, 0.7843382039411015, 0.7082711720504129, 611, 5, 2]\n",
      "0.8697199999999999\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 110.2283\n",
      "Function value obtained: -0.8179\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "[0.09337439680225655, 6, 18, 0.7861462430096181, 0.2729587719488105, 395, 4, 3]\n",
      "0.8695200000000001\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 98.8684\n",
      "Function value obtained: -0.8175\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "[0.09953682534205655, 5, 6, 0.7808766527545805, 0.7603290693718262, 239, 4, 4]\n",
      "0.85476\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 146.5501\n",
      "Function value obtained: -0.7981\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "[0.08849922142035041, 8, 19, 0.08432046103576706, 0.8814795401173019, 705, 3, 3]\n",
      "0.8453599999999999\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 118.4004\n",
      "Function value obtained: -0.7913\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "[0.09882443361670419, 2, 10, 0.9062870296981735, 0.13390121290136836, 726, 4, 1]\n",
      "0.85952\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.3154\n",
      "Function value obtained: -0.8019\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "[0.04952820076803324, 4, 14, 0.867481825884715, 0.23257723321042478, 797, 5, 2]\n",
      "0.86644\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 79.6304\n",
      "Function value obtained: -0.8121\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "[0.02611178575491709, 4, 15, 0.905482401090545, 0.7141853045528769, 934, 4, 2]\n",
      "0.85\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 118.1709\n",
      "Function value obtained: -0.7908\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "[0.06185717265722517, 1, 5, 0.9726454465073857, 0.2720370485891986, 791, 2, 5]\n",
      "0.82696\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 163.4751\n",
      "Function value obtained: -0.7618\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "[0.06110231628986924, 6, 1, 0.972987952445139, 0.2561588031911553, 542, 5, 5]\n",
      "0.86608\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 283.6956\n",
      "Function value obtained: -0.8139\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "[0.024778187660692747, 4, 6, 0.7729224555235892, 0.7695949586006949, 837, 5, 2]\n",
      "0.8482800000000001\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 145.5430\n",
      "Function value obtained: -0.7884\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "[0.09842758198209754, 10, 16, 0.9724842426808487, 0.25950153117857255, 301, 5, 2]\n",
      "0.86664\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 113.2422\n",
      "Function value obtained: -0.8148\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "[0.09491713922674694, 4, 10, 0.09367822995359221, 0.1455124298339864, 376, 2, 2]\n",
      "0.85684\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 46.8066\n",
      "Function value obtained: -0.8027\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "[0.06657330320064159, 10, 16, 0.9865411361845817, 0.2161385490356743, 108, 5, 1]\n",
      "0.8383999999999999\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 36.1658\n",
      "Function value obtained: -0.7774\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "[0.04862572528968177, 5, 20, 0.436065063904341, 0.3176564527531764, 782, 4, 1]\n",
      "0.86872\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 40.0899\n",
      "Function value obtained: -0.8153\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "[0.037922373617680694, 5, 15, 0.27384632440075624, 0.33915986333728254, 695, 4, 1]\n",
      "0.86348\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 34.9563\n",
      "Function value obtained: -0.8087\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "[0.042325905104952634, 5, 12, 0.6144494416810199, 0.9656399474664887, 538, 5, 5]\n",
      "0.85884\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 203.5166\n",
      "Function value obtained: -0.8026\n",
      "Current minimum: -0.8231\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "[0.024737476110378367, 5, 20, 0.884247933654632, 0.17189660310123273, 616, 2, 5]\n",
      "0.84292\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 171.8233\n",
      "Function value obtained: -0.7828\n",
      "Current minimum: -0.8231\n"
     ]
    }
   ],
   "source": [
    "def tune_lgbm(params):\n",
    "    print(params)\n",
    "    lr = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    n_estimators = params[5]\n",
    "    \n",
    "    min_df = params[6]\n",
    "    ngram_range = (1, params[7])\n",
    "    \n",
    "    tfidf = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "    Xtrain_vec = tfidf.fit_transform(Xtrain)\n",
    "    Xtest_vec = tfidf.transform(Xtest)\n",
    "    \n",
    "    lgbm = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                         min_child_samples=min_child_samples, subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                         class_weight=\"balanced\", n_jobs=6)\n",
    "    lgbm.fit(Xtrain_vec, ytrain)\n",
    "    \n",
    "    ypred_lgbm = lgbm.predict(Xtest_vec)\n",
    "    \n",
    "    print(roc_auc_score(ytest, ypred_lgbm))\n",
    "    \n",
    "    return -average_precision_score(ytest, ypred_lgbm)\n",
    "\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), # lr\n",
    "          (1, 10), # max_depth\n",
    "          (1, 20), # min_child_samples\n",
    "          (0.05, 1.), # subsample\n",
    "          (0.05, 1.), # colsample_bytree\n",
    "          (100,1000), # n_estimators\n",
    "          (1,5), # min_df\n",
    "          (1,5)] # ngram_range\n",
    "\n",
    "res = forest_minimize(tune_lgbm, space, random_state=79, n_random_starts=20, n_calls=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Após 50 iterações, verificamos o conjunto de hiperparâmetros que nos deu a melhor métrica.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09431638480128277, 4, 3, 0.6295926398680836, 0.34512927281549965, 815, 3, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Com a <i>Otimização Bayesiana</i> conseguimos os melhores hiperparâmetros para o <i>LightGBM</i>, vamos verificar as metricas com o modelo treinado.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc:\t0.8740799999999999\n",
      "accuracy:\t0.87408\n",
      "f1 score:\t0.8758577174856061\n",
      "avg precision:\t0.823079670244206\n"
     ]
    }
   ],
   "source": [
    "params = res.x\n",
    "lr = params[0]\n",
    "max_depth = params[1]\n",
    "min_child_samples = params[2]\n",
    "subsample = params[3]\n",
    "colsample_bytree = params[4]\n",
    "n_estimators = params[5]\n",
    "min_df = params[6]\n",
    "ngram_range = (1, params[7])\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "Xtrain_vec = tfidf.fit_transform(Xtrain)\n",
    "Xtest_vec = tfidf.transform(Xtest)\n",
    "\n",
    "lgbm = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                     min_child_samples=min_child_samples, subsample=subsample,\n",
    "                     colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                     class_weight=\"balanced\", n_jobs=6)\n",
    "lgbm.fit(Xtrain_vec, ytrain)\n",
    "ypred_lgbm = lgbm.predict(Xtest_vec)\n",
    "\n",
    "roc_auc_lgbm = roc_auc_score(ytest, ypred_lgbm)\n",
    "acc_lgbm = accuracy_score(ytest, ypred_lgbm)\n",
    "f1_lgbm = f1_score(ytest, ypred_lgbm)\n",
    "avg_prec_lgbm = average_precision_score(ytest, ypred_lgbm)\n",
    "print('roc auc:\\t{}\\naccuracy:\\t{}\\nf1 score:\\t{}\\navg precision:\\t{}'.format(roc_auc_lgbm, acc_lgbm,\n",
    "                                                                              f1_lgbm, avg_prec_lgbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Agora com todos os modelos testados, podemos ver que o que tem a melhor performance é a <i>Regressão Logística</i>. Para tentarmos melhorar essas métricas fazendo um ensemble dos modelos.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='VOT'></a>\n",
    "<h2>Voting</h2>\n",
    "\n",
    "<font size=3>Uma tentativa de melhorar as métricas do nosso modelo seria fazer um ensemble dos modelos que treinamos.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc:\t0.886\n",
      "accuracy:\t0.886\n",
      "f1 score:\t0.8871465906391066\n",
      "avg precision:\t0.8390286968794103\n"
     ]
    }
   ],
   "source": [
    "params = res.x\n",
    "learn_rate = params[0]\n",
    "max_depth = params[1]\n",
    "min_child_samples = params[2]\n",
    "subsample = params[3]\n",
    "colsample_bytree = params[4]\n",
    "n_estimators = params[5]\n",
    "min_df = params[6]\n",
    "ngram_range = (1, params[7])\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "Xtrain_vec = tfidf.fit_transform(Xtrain)\n",
    "Xtest_vec = tfidf.transform(Xtest)\n",
    "\n",
    "lr = LogisticRegression(random_state=79)\n",
    "rf = RandomForestClassifier(n_estimators=1000, min_samples_leaf=2, class_weight='balanced', n_jobs=5, random_state=79)\n",
    "lgbm = LGBMClassifier(learning_rate=learn_rate, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                     min_child_samples=min_child_samples, subsample=subsample,\n",
    "                     colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                     class_weight=\"balanced\", n_jobs=6)\n",
    "\n",
    "vot = VotingClassifier(estimators=[('lr', lr), ('rf', rf), ('lgbm', lgbm)], voting='soft')\n",
    "vot.fit(Xtrain_vec, ytrain)\n",
    "ypred_vot = vot.predict(Xtest_vec)\n",
    "\n",
    "roc_auc_vot = roc_auc_score(ytest, ypred_vot)\n",
    "acc_vot = accuracy_score(ytest, ypred_vot)\n",
    "f1_vot = f1_score(ytest, ypred_vot)\n",
    "avg_prec_vot = average_precision_score(ytest, ypred_vot)\n",
    "print('roc auc:\\t{}\\naccuracy:\\t{}\\nf1 score:\\t{}\\navg precision:\\t{}'.format(roc_auc_vot, acc_vot,\n",
    "                                                                              f1_vot, avg_prec_vot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Com as métricas acima podemos verificar que mesmo usando <i>Voting</i> não conseguimos bater a <i>Regressão Logística</i>.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
